{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a2120e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2d2e6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 26 17:32:52 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\r\n",
      "| 28%   37C    P8    16W / 260W |    332MiB / 11016MiB |      2%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA GeForce ...  On   | 00000000:02:00.0 Off |                  N/A |\r\n",
      "| 35%   51C    P2   231W / 250W |   2102MiB / 11019MiB |     99%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1308      G   /usr/lib/xorg/Xorg                 18MiB |\r\n",
      "|    0   N/A  N/A      1392      G   /usr/bin/gnome-shell               72MiB |\r\n",
      "|    0   N/A  N/A      1783      G   /usr/lib/xorg/Xorg                167MiB |\r\n",
      "|    0   N/A  N/A      1915      G   /usr/bin/gnome-shell               18MiB |\r\n",
      "|    0   N/A  N/A      2579      G   /usr/bin/anydesk                   19MiB |\r\n",
      "|    0   N/A  N/A      3142      G   ...gAAAAAAAAA --shared-files       28MiB |\r\n",
      "|    0   N/A  N/A     14971      G   ...f_2430.log --shared-files        3MiB |\r\n",
      "|    1   N/A  N/A      1308      G   /usr/lib/xorg/Xorg                  4MiB |\r\n",
      "|    1   N/A  N/A      1783      G   /usr/lib/xorg/Xorg                  4MiB |\r\n",
      "|    1   N/A  N/A     22943      C   ...r_learning_env/bin/python     2089MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4897f89",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16770/3419912370.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_VISIBLE_DEVICES'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'0'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Marwa/Environments/deep_transfer_learning_env/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36msynchronize\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_synchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "torch.cuda.empty_cache()\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "567879e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16770/757682430.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_allocated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_allocated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Marwa/Environments/deep_transfer_learning_env/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36msynchronize\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_synchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "print(torch.cuda.memory_allocated())\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "print(torch.cuda.memory_allocated())\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "print(torch.cuda.memory_allocated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608a522a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d1c7301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 S root      1057     1  0  80   0 - 42635 -      12:48 ?        00:00:00 /usr/bin/python3 /usr/bin/networkd-dispatcher --run-startup-triggers\r\n",
      "4 S root      1240     1  0  80   0 - 46814 -      12:48 ?        00:00:00 /usr/bin/python3 /usr/share/unattended-upgrades/unattended-upgrade-shutdown --wait-for-signal\r\n",
      "0 S mostafa   3737  3713  0  80   0 - 61836 ep_pol 12:52 pts/0    00:00:08 /home/mostafa/Marwa/Environments/nicMSlesion_env/bin/python /home/mostafa/Marwa/Environments/nicMSlesion_env/bin/jupyter-notebook\r\n",
      "0 S mostafa   3846  3737  0  80   0 - 190241 ep_pol 12:52 ?       00:00:00 /home/mostafa/Marwa/Environments/nicMSlesion_env/bin/python -m ipykernel_launcher -f /home/mostafa/.local/share/jupyter/runtime/kernel-667ab459-776d-4525-9e52-7d661c8fd42d.json\r\n",
      "0 S mostafa   4010  3737  0  80   0 - 4201853 ep_pol 12:53 ?      00:00:05 /home/mostafa/Marwa/Environments/nicMSlesion_env/bin/python -m ipykernel_launcher -f /home/mostafa/.local/share/jupyter/runtime/kernel-f0b43fe9-59e1-4943-9953-0c9c60c0a218.json\r\n",
      "0 S mostafa   7051  3737  0  80   0 - 190043 ep_pol 13:23 ?       00:00:00 /home/mostafa/Marwa/Environments/nicMSlesion_env/bin/python -m ipykernel_launcher -f /home/mostafa/.local/share/jupyter/runtime/kernel-61d5be58-80b1-40b9-94d1-726b62a0c6e2.json\r\n",
      "0 S mostafa  14917  2430  0  80   0 - 163467 futex_ 14:29 tty2    00:00:05 /home/mostafa/Marwa/Environments/nicMSlesion_env/bin/python /snap/pycharm-educational/44/plugins/python-ce/helpers/pydev/pydevconsole.py --mode=client --port=40677\r\n",
      "0 S mostafa  15640  3737  2  80   0 - 8276608 ep_pol 14:46 ?      00:01:07 /home/mostafa/Marwa/Environments/nicMSlesion_env/bin/python -m ipykernel_launcher -f /home/mostafa/.local/share/jupyter/runtime/kernel-aae8b9e1-fd3e-45eb-9ef3-2e444fa13e3c.json\r\n",
      "0 S mostafa  15912  3737  1  80   0 - 10100177 ep_pol 14:53 ?     00:00:29 /home/mostafa/Marwa/Environments/nicMSlesion_env/bin/python -m ipykernel_launcher -f /home/mostafa/.local/share/jupyter/runtime/kernel-1bc019e3-a568-438b-948f-aa88de863e09.json\r\n",
      "0 S mostafa  16611 16580  0  80   0 - 60820 ep_pol 15:09 pts/2    00:00:01 /home/mostafa/Marwa/Environments/deep_transfer_learning_env/bin/python /home/mostafa/Marwa/Environments/deep_transfer_learning_env/bin/jupyter-notebook\r\n",
      "0 S mostafa  16770 16611  0  80   0 - 3040098 poll_s 15:09 ?      00:00:01 /home/mostafa/Marwa/Environments/deep_transfer_learning_env/bin/python -m ipykernel_launcher -f /home/mostafa/.local/share/jupyter/runtime/kernel-0b96dbee-b8a7-4991-a9e6-6d91f20d1fb2.json\r\n",
      "0 S mostafa  18115 16770  0  80   0 -  3224 wait   15:32 pts/3    00:00:00 /bin/bash -c ps -elf | grep python\r\n",
      "0 S mostafa  18117 18115  0  80   0 -  3610 pipe_w 15:32 pts/3    00:00:00 grep python\r\n"
     ]
    }
   ],
   "source": [
    "#some Python subprocesses are still alive. You may find them via\n",
    "!ps -elf | grep python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19b3f95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 0: kill: (1240) - Operation not permitted\r\n"
     ]
    }
   ],
   "source": [
    "!kill -9 1240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37daa8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available?  True\n",
      "cuda count  2\n",
      "current device  1\n",
      "current device  1\n",
      "current device  1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "print('cuda available? ', torch.cuda.is_available())\n",
    "print('cuda count ', torch.cuda.device_count())\n",
    "print('current device ',torch.cuda.current_device())\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "print('current device ',torch.cuda.current_device())\n",
    "\n",
    "torch.cuda.set_device(1)\n",
    "print('current device ',torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5abc9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 2080 Ti\n",
      "NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.get_device_name(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f900d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 26 15:27:35 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\r\n",
      "| 28%   35C    P8    11W / 260W |  10975MiB / 11016MiB |      1%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA GeForce ...  On   | 00000000:02:00.0 Off |                  N/A |\r\n",
      "| 27%   33C    P8     6W / 250W |  10810MiB / 11019MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1308      G   /usr/lib/xorg/Xorg                 18MiB |\r\n",
      "|    0   N/A  N/A      1392      G   /usr/bin/gnome-shell               72MiB |\r\n",
      "|    0   N/A  N/A      1783      G   /usr/lib/xorg/Xorg                146MiB |\r\n",
      "|    0   N/A  N/A      1915      G   /usr/bin/gnome-shell               27MiB |\r\n",
      "|    0   N/A  N/A      2579      G   /usr/bin/anydesk                   19MiB |\r\n",
      "|    0   N/A  N/A      3142      G   ...gAAAAAAAAA --shared-files       62MiB |\r\n",
      "|    0   N/A  N/A      4010      C   ...icMSlesion_env/bin/python      297MiB |\r\n",
      "|    0   N/A  N/A     14971      G   ...f_2430.log --shared-files        3MiB |\r\n",
      "|    0   N/A  N/A     15640      C   ...icMSlesion_env/bin/python     9775MiB |\r\n",
      "|    0   N/A  N/A     15912      C   ...icMSlesion_env/bin/python      545MiB |\r\n",
      "|    1   N/A  N/A      1308      G   /usr/lib/xorg/Xorg                  4MiB |\r\n",
      "|    1   N/A  N/A      1783      G   /usr/lib/xorg/Xorg                  4MiB |\r\n",
      "|    1   N/A  N/A      4010      C   ...icMSlesion_env/bin/python      297MiB |\r\n",
      "|    1   N/A  N/A     15640      C   ...icMSlesion_env/bin/python      297MiB |\r\n",
      "|    1   N/A  N/A     15912      C   ...icMSlesion_env/bin/python    10203MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "912d79b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2578344406.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_31255/2578344406.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    watch -n 1 nvidia-smi\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "watch -n 2 nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69dcb203",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.cuda' has no attribute 'clear_memory_allocated'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16770/3950294382.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_memory_allocated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.cuda' has no attribute 'clear_memory_allocated'"
     ]
    }
   ],
   "source": [
    "torch.cuda.clear_memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b121322b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83e41d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_loader import *\n",
    "from config.settings import *\n",
    "import dataset_loader as dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79e037b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = Settings()\n",
    "options = st.get_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b21c2813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.1'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "405b36c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "nn.AvgPool3d?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a10f3883",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'source_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17642/1656054068.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen_source_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0miter_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnum_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen_source_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdata_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter_source\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'source_loader' is not defined"
     ]
    }
   ],
   "source": [
    "len_source_loader = len(source_loader)\n",
    "iter_source = iter(source_loader)\n",
    "num_iter = len_source_loader\n",
    "for i in range(1, num_iter):\n",
    "    data_source, label_source = iter_source.next()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f31cea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= enumerate(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "198e95d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/microsoft/Medical_Analysis/Code/Environments/medical_pytorch_env/lib/python3.7/site-packages/sklearn/model_selection/_split.py:668: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from utils.data_preprocess import *\n",
    "df = generate_csv(options)\n",
    "split_folds(options['train_csv_path'], options['seed'], options['k_fold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c114eb90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['root_path', 'patient_id', 'study', 'lesion', 'FLAIR', 'T1', 'fold'], dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ccce29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "48203c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([['training01', '_01'],\n",
       "        ['training02', '_04'],\n",
       "        ['training03', '_02'],\n",
       "        ['training04', '_02'],\n",
       "        ['training05', '_02']], dtype=object),\n",
       " ['training01_01',\n",
       "  'training02_04',\n",
       "  'training03_02',\n",
       "  'training04_02',\n",
       "  'training05_02'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8602c9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['training01_01',\n",
       " 'training01_02',\n",
       " 'training01_03',\n",
       " 'training01_04',\n",
       " 'training02_01',\n",
       " 'training02_02',\n",
       " 'training02_03',\n",
       " 'training02_04',\n",
       " 'training03_01',\n",
       " 'training03_02',\n",
       " 'training03_03',\n",
       " 'training03_04',\n",
       " 'training03_05',\n",
       " 'training04_01',\n",
       " 'training04_02',\n",
       " 'training04_03',\n",
       " 'training04_04',\n",
       " 'training05_01',\n",
       " 'training05_02',\n",
       " 'training05_03',\n",
       " 'training05_04']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scan_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e8a929",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
